{"cells":[{"cell_type":"code","execution_count":1,"id":"d9644b1c","metadata":{"id":"FC9270291C384CF49A8B87314B9EAE0F","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"import pathlib\nimport tensorflow  as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import layers,models\nimport matplotlib.pyplot as plt"},{"cell_type":"code","execution_count":2,"id":"eeff8b8e","metadata":{"id":"0A031AD7D21540969D9A606B1315D35C","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Angelina Jolie\t   Johnny Depp\t      Nicole Kidman\t  Tom Hanks\r\nBrad Pitt\t   Kate Winslet       Robert Downey Jr\t  Will Smith\r\nDenzel Washington  Leonardo DiCaprio  Sandra Bullock\r\nHugh Jackman\t   Megan Fox\t      Scarlett Johansson\r\nJennifer Lawrence  Natalie Portman    Tom Cruise\r\n"}],"source":"!ls /home/mw/input/99119154/people_data/people_data/48-data"},{"cell_type":"markdown","id":"516d36ba","metadata":{"id":"D145128E973942BF85E65784A59A8095","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"source":"## 学习如何使用pathlib"},{"cell_type":"code","execution_count":3,"id":"40749716","metadata":{"id":"7360B172097443FEA3A6670E7A332E68","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"path = pathlib.Path('/home/mw/input/99119154/people_data/people_data/48-data')"},{"cell_type":"code","execution_count":4,"id":"38cf5fae","metadata":{"id":"AF3149589A2046A69485D30A9B7BA9AC","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":"PosixPath('/home/mw/input/99119154/people_data/people_data')"},"metadata":{},"transient":{},"execution_count":4}],"source":"path.parent # 父级"},{"cell_type":"code","execution_count":5,"id":"17ff841a","metadata":{"id":"2C112B27E0A24E78BC67BB20382D8BF4","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":"'48-data'"},"metadata":{},"transient":{},"execution_count":5}],"source":"path.name # 名称"},{"cell_type":"code","execution_count":6,"id":"8bacf846","metadata":{"id":"E505FDAAF7BD4A45BCB81934AAA3CDC3","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"images = list(path.rglob('*.jpg')) # 使用rglob递归获取全部图片,这里使用正则表达式来获取"},{"cell_type":"code","execution_count":7,"id":"c0fd5e1b","metadata":{"id":"7B740F7259834C93ABD0005D9A791AE1","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"1800\n"}],"source":"print(len(images))"},{"cell_type":"code","execution_count":8,"id":"2913fa02","metadata":{"id":"953840493F424BFEB95B4F0409D8A16B","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"from PIL import Image"},{"cell_type":"code","execution_count":9,"id":"717fe3dc","metadata":{"id":"513FF28A08084F139E0D3DE590E85573","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"474 568\n"}],"source":"image = Image.open(images[9])\nprint(image.width,image.height) # 获取图片的宽和高"},{"cell_type":"code","execution_count":10,"id":"36e94918","metadata":{"id":"6395B1D93F974F219F72193C3B38F7A0","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"batch_size = 32 # 设置batch_szie\nimg_height = 224\nimg_width = 224"},{"cell_type":"markdown","id":"b53c7fdd","metadata":{"id":"ECB88D6921924CDCA50E74328BF9C21C","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"source":"## 设置训练集与验证集"},{"cell_type":"code","execution_count":11,"id":"afd257ee","metadata":{"id":"56BB43B7C91D473283A92196EF011995","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Found 1800 files belonging to 17 classes.\nUsing 1620 files for training.\n"}],"source":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    path,\n    validation_split=0.1,\n    subset=\"training\",\n    label_mode = \"categorical\", # 标签将被编码为分类向量，一共17个类别\n    seed=123, # 随机种子的设置\n    image_size=(img_height, img_width), # 将图片重新resize\n    batch_size=batch_size) # batch_size的大小\n"},{"cell_type":"code","execution_count":12,"id":"f25c49b5","metadata":{"id":"26C2339144AF41C69FD0303401058B3D","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Found 1800 files belonging to 17 classes.\nUsing 180 files for validation.\n"}],"source":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    path,\n    validation_split=0.1,\n    subset=\"validation\",\n    label_mode = \"categorical\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size)\n"},{"cell_type":"code","execution_count":13,"id":"3fa751b2","metadata":{"id":"7F713994D14642EA98E20990733CC299","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"['Angelina Jolie', 'Brad Pitt', 'Denzel Washington', 'Hugh Jackman', 'Jennifer Lawrence', 'Johnny Depp', 'Kate Winslet', 'Leonardo DiCaprio', 'Megan Fox', 'Natalie Portman', 'Nicole Kidman', 'Robert Downey Jr', 'Sandra Bullock', 'Scarlett Johansson', 'Tom Cruise', 'Tom Hanks', 'Will Smith']\n"}],"source":"class_names = train_ds.class_names\nprint(class_names) # 查看分类"},{"cell_type":"code","execution_count":14,"id":"ff2105f5","metadata":{"id":"941575156DEA4AED84210E8E32565684","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"(32, 224, 224, 3)\n(32, 17)\n"}],"source":"for image,labels in train_ds: # 查看数据集个数\n    print(image.shape)\n    print(labels.shape)\n    break"},{"cell_type":"code","execution_count":15,"id":"0c15ffd3","metadata":{"id":"6D5A1140A406483D96B016EAF5B17488","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"AUTOTUNE = tf.data.AUTOTUNE"},{"cell_type":"code","execution_count":16,"id":"0740523c","metadata":{"id":"F698B6E6EE544FFF984664E0DC5C8EC4","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"#设置预加载\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"},{"cell_type":"code","execution_count":31,"id":"4cf71afc","metadata":{"id":"196151C8C45148E69C3097DD8D9004B5","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nrescaling (Rescaling)        (None, 224, 224, 3)       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 222, 222, 16)      448       \n_________________________________________________________________\naverage_pooling2d (AveragePo (None, 111, 111, 16)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 109, 109, 32)      4640      \n_________________________________________________________________\naverage_pooling2d_1 (Average (None, 54, 54, 32)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 54, 54, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 52, 52, 64)        18496     \n_________________________________________________________________\naverage_pooling2d_2 (Average (None, 26, 26, 64)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 26, 26, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 24, 24, 128)       73856     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 24, 24, 128)       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 73728)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               9437312   \n_________________________________________________________________\ndense_1 (Dense)              (None, 17)                2193      \n=================================================================\nTotal params: 9,536,945\nTrainable params: 9,536,945\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":"model = models.Sequential([\n    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)), # 卷积层1，卷积核3*3  \n    layers.AveragePooling2D((2, 2)),               # 池化层1，2*2采样\n    layers.Conv2D(32, (3, 3), activation='relu'),  # 卷积层2，卷积核3*3\n    layers.AveragePooling2D((2, 2)),               # 池化层2，2*2采样\n    layers.Dropout(0.5),  \n    layers.Conv2D(64, (3, 3), activation='relu'),  # 卷积层3，卷积核3*3\n    layers.AveragePooling2D((2, 2)),     \n    layers.Dropout(0.5),  \n    layers.Conv2D(128, (3, 3), activation='relu'),  # 卷积层3，卷积核3*3\n    layers.Dropout(0.5), \n    \n    layers.Flatten(),                       # Flatten层，连接卷积层与全连接层\n    layers.Dense(128, activation='relu'),   # 全连接层，特征进一步提取\n    layers.Dense(len(class_names))               # 输出层，输出预期结果\n])\n\nmodel.summary()  # 打印网络结构"},{"cell_type":"code","execution_count":32,"id":"60139384","metadata":{"id":"BB2479ABE60B4DD698498E7AD8784149","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"optimizer = tf.keras.optimizers.Adam()\n\nmodel.compile(optimizer=optimizer,\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])"},{"cell_type":"code","execution_count":33,"id":"4bcda6ba","metadata":{"id":"068865A851014DB2AA18E4C61F9BB718","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"\nepochs = 100\n\n# 保存最佳模型参数\ncheckpointer = ModelCheckpoint('best_model.h5',\n                                monitor='val_accuracy',\n                                verbose=1,\n                                save_best_only=True,\n                                save_weights_only=True)"},{"cell_type":"code","execution_count":34,"id":"89606fa5","metadata":{"id":"5E773CD271534CB2B455C347D210316C","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/50\n51/51 [==============================] - 8s 47ms/step - loss: 2.8659 - accuracy: 0.1117 - val_loss: 2.7818 - val_accuracy: 0.1389\n\nEpoch 00001: val_accuracy improved from -inf to 0.13889, saving model to best_model.h5\nEpoch 2/50\n51/51 [==============================] - 1s 26ms/step - loss: 2.7472 - accuracy: 0.1190 - val_loss: 2.6347 - val_accuracy: 0.0833\n\nEpoch 00002: val_accuracy did not improve from 0.13889\nEpoch 3/50\n51/51 [==============================] - 1s 27ms/step - loss: 2.4912 - accuracy: 0.1929 - val_loss: 2.4912 - val_accuracy: 0.2389\n\nEpoch 00003: val_accuracy improved from 0.13889 to 0.23889, saving model to best_model.h5\nEpoch 4/50\n51/51 [==============================] - 1s 27ms/step - loss: 2.2640 - accuracy: 0.2605 - val_loss: 2.3687 - val_accuracy: 0.2500\n\nEpoch 00004: val_accuracy improved from 0.23889 to 0.25000, saving model to best_model.h5\nEpoch 5/50\n51/51 [==============================] - 1s 26ms/step - loss: 2.0098 - accuracy: 0.3570 - val_loss: 2.3225 - val_accuracy: 0.2667\n\nEpoch 00005: val_accuracy improved from 0.25000 to 0.26667, saving model to best_model.h5\nEpoch 6/50\n51/51 [==============================] - 1s 26ms/step - loss: 1.7231 - accuracy: 0.4300 - val_loss: 2.4573 - val_accuracy: 0.3056\n\nEpoch 00006: val_accuracy improved from 0.26667 to 0.30556, saving model to best_model.h5\nEpoch 7/50\n51/51 [==============================] - 1s 26ms/step - loss: 1.3647 - accuracy: 0.5632 - val_loss: 2.2480 - val_accuracy: 0.3500\n\nEpoch 00007: val_accuracy improved from 0.30556 to 0.35000, saving model to best_model.h5\nEpoch 8/50\n51/51 [==============================] - 1s 27ms/step - loss: 1.0356 - accuracy: 0.6536 - val_loss: 2.4978 - val_accuracy: 0.3222\n\nEpoch 00008: val_accuracy did not improve from 0.35000\nEpoch 9/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.7116 - accuracy: 0.7637 - val_loss: 2.8888 - val_accuracy: 0.3333\n\nEpoch 00009: val_accuracy did not improve from 0.35000\nEpoch 10/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.5275 - accuracy: 0.8303 - val_loss: 2.8839 - val_accuracy: 0.3833\n\nEpoch 00010: val_accuracy improved from 0.35000 to 0.38333, saving model to best_model.h5\nEpoch 11/50\n51/51 [==============================] - 1s 26ms/step - loss: 0.3700 - accuracy: 0.8687 - val_loss: 3.3624 - val_accuracy: 0.4056\n\nEpoch 00011: val_accuracy improved from 0.38333 to 0.40556, saving model to best_model.h5\nEpoch 12/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.2624 - accuracy: 0.9213 - val_loss: 3.7723 - val_accuracy: 0.3889\n\nEpoch 00012: val_accuracy did not improve from 0.40556\nEpoch 13/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.2854 - accuracy: 0.9072 - val_loss: 3.5393 - val_accuracy: 0.3833\n\nEpoch 00013: val_accuracy did not improve from 0.40556\nEpoch 14/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.2022 - accuracy: 0.9346 - val_loss: 4.4753 - val_accuracy: 0.3778\n\nEpoch 00014: val_accuracy did not improve from 0.40556\nEpoch 15/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.2088 - accuracy: 0.9307 - val_loss: 3.8104 - val_accuracy: 0.4000\n\nEpoch 00015: val_accuracy did not improve from 0.40556\nEpoch 16/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.1484 - accuracy: 0.9495 - val_loss: 4.3115 - val_accuracy: 0.3722\n\nEpoch 00016: val_accuracy did not improve from 0.40556\nEpoch 17/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.1350 - accuracy: 0.9627 - val_loss: 4.9655 - val_accuracy: 0.3833\n\nEpoch 00017: val_accuracy did not improve from 0.40556\nEpoch 18/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0843 - accuracy: 0.9743 - val_loss: 5.2685 - val_accuracy: 0.4111\n\nEpoch 00018: val_accuracy improved from 0.40556 to 0.41111, saving model to best_model.h5\nEpoch 19/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.1465 - accuracy: 0.9579 - val_loss: 4.5932 - val_accuracy: 0.3667\n\nEpoch 00019: val_accuracy did not improve from 0.41111\nEpoch 20/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0804 - accuracy: 0.9745 - val_loss: 4.6689 - val_accuracy: 0.4056\n\nEpoch 00020: val_accuracy did not improve from 0.41111\nEpoch 21/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.1073 - accuracy: 0.9654 - val_loss: 4.9352 - val_accuracy: 0.3889\n\nEpoch 00021: val_accuracy did not improve from 0.41111\nEpoch 22/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0903 - accuracy: 0.9724 - val_loss: 5.0001 - val_accuracy: 0.3722\n\nEpoch 00022: val_accuracy did not improve from 0.41111\nEpoch 23/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.1127 - accuracy: 0.9641 - val_loss: 4.7852 - val_accuracy: 0.3778\n\nEpoch 00023: val_accuracy did not improve from 0.41111\nEpoch 24/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0606 - accuracy: 0.9803 - val_loss: 5.1896 - val_accuracy: 0.3722\n\nEpoch 00024: val_accuracy did not improve from 0.41111\nEpoch 25/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0761 - accuracy: 0.9723 - val_loss: 6.1582 - val_accuracy: 0.4111\n\nEpoch 00025: val_accuracy did not improve from 0.41111\nEpoch 26/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0993 - accuracy: 0.9652 - val_loss: 5.2899 - val_accuracy: 0.3833\n\nEpoch 00026: val_accuracy did not improve from 0.41111\nEpoch 27/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0613 - accuracy: 0.9788 - val_loss: 5.5547 - val_accuracy: 0.3667\n\nEpoch 00027: val_accuracy did not improve from 0.41111\nEpoch 28/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0906 - accuracy: 0.9694 - val_loss: 5.5128 - val_accuracy: 0.3778\n\nEpoch 00028: val_accuracy did not improve from 0.41111\nEpoch 29/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0393 - accuracy: 0.9865 - val_loss: 6.1578 - val_accuracy: 0.3722\n\nEpoch 00029: val_accuracy did not improve from 0.41111\nEpoch 30/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0785 - accuracy: 0.9772 - val_loss: 5.4651 - val_accuracy: 0.3833\n\nEpoch 00030: val_accuracy did not improve from 0.41111\nEpoch 31/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0549 - accuracy: 0.9811 - val_loss: 6.1985 - val_accuracy: 0.3444\n\nEpoch 00031: val_accuracy did not improve from 0.41111\nEpoch 32/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0607 - accuracy: 0.9844 - val_loss: 5.3177 - val_accuracy: 0.3500\n\nEpoch 00032: val_accuracy did not improve from 0.41111\nEpoch 33/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 5.1937 - val_accuracy: 0.3944\n\nEpoch 00033: val_accuracy did not improve from 0.41111\nEpoch 34/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0252 - accuracy: 0.9936 - val_loss: 5.9467 - val_accuracy: 0.3778\n\nEpoch 00034: val_accuracy did not improve from 0.41111\nEpoch 35/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0494 - accuracy: 0.9844 - val_loss: 5.4619 - val_accuracy: 0.3667\n\nEpoch 00035: val_accuracy did not improve from 0.41111\nEpoch 36/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0377 - accuracy: 0.9881 - val_loss: 5.9611 - val_accuracy: 0.4111\n\nEpoch 00036: val_accuracy did not improve from 0.41111\nEpoch 37/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0391 - accuracy: 0.9855 - val_loss: 5.5441 - val_accuracy: 0.4056\n\nEpoch 00037: val_accuracy did not improve from 0.41111\nEpoch 38/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 6.5436 - val_accuracy: 0.3444\n\nEpoch 00038: val_accuracy did not improve from 0.41111\nEpoch 39/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0560 - accuracy: 0.9819 - val_loss: 5.8862 - val_accuracy: 0.3722\n\nEpoch 00039: val_accuracy did not improve from 0.41111\nEpoch 40/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0323 - accuracy: 0.9912 - val_loss: 5.8621 - val_accuracy: 0.3833\n\nEpoch 00040: val_accuracy did not improve from 0.41111\nEpoch 41/50\n51/51 [==============================] - 1s 28ms/step - loss: 0.0310 - accuracy: 0.9857 - val_loss: 6.0268 - val_accuracy: 0.3889\n\nEpoch 00041: val_accuracy did not improve from 0.41111\nEpoch 42/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0196 - accuracy: 0.9925 - val_loss: 6.6835 - val_accuracy: 0.3833\n\nEpoch 00042: val_accuracy did not improve from 0.41111\nEpoch 43/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0436 - accuracy: 0.9878 - val_loss: 5.9874 - val_accuracy: 0.3556\n\nEpoch 00043: val_accuracy did not improve from 0.41111\nEpoch 44/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0751 - accuracy: 0.9740 - val_loss: 5.9016 - val_accuracy: 0.3722\n\nEpoch 00044: val_accuracy did not improve from 0.41111\nEpoch 45/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0465 - accuracy: 0.9808 - val_loss: 6.0599 - val_accuracy: 0.3611\n\nEpoch 00045: val_accuracy did not improve from 0.41111\nEpoch 46/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0582 - accuracy: 0.9803 - val_loss: 5.8313 - val_accuracy: 0.3889\n\nEpoch 00046: val_accuracy did not improve from 0.41111\nEpoch 47/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0265 - accuracy: 0.9946 - val_loss: 6.2619 - val_accuracy: 0.4222\n\nEpoch 00047: val_accuracy improved from 0.41111 to 0.42222, saving model to best_model.h5\nEpoch 48/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0304 - accuracy: 0.9914 - val_loss: 6.4928 - val_accuracy: 0.3333\n\nEpoch 00048: val_accuracy did not improve from 0.42222\nEpoch 49/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0340 - accuracy: 0.9874 - val_loss: 6.1544 - val_accuracy: 0.3611\n\nEpoch 00049: val_accuracy did not improve from 0.42222\nEpoch 50/50\n51/51 [==============================] - 1s 27ms/step - loss: 0.0201 - accuracy: 0.9951 - val_loss: 5.9560 - val_accuracy: 0.4056\n\nEpoch 00050: val_accuracy did not improve from 0.42222\n"}],"source":"history = model.fit(train_ds,\n                    validation_data=val_ds,\n                    epochs=50\n                   ,callbacks=[checkpointer]) # 这里要将callbacks传入参数，否则保存没有效果。"},{"cell_type":"code","execution_count":35,"id":"271aa6f8","metadata":{"id":"D9ED8545BC654DE29830DA0898289C88","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x288 with 2 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/D9ED8545BC654DE29830DA0898289C88/rhhfig4k2c.png\">"},"metadata":{"needs_background":"light"},"transient":{}}],"source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(loss))\n\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()"},{"cell_type":"code","execution_count":38,"id":"37a687fc","metadata":{"id":"AC7BDD23D99B4D45B945157AA765605D","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"model.load_weights('./best_model.h5')"},{"cell_type":"markdown","id":"c9b89abb","metadata":{"id":"71A61F1751374AE7ABCC126C066EA9DB","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"source":"## 使用VGG\nvgg使用3*3卷积核，以及更深的网络。vgg的特点是每层输出的时候把w,h减半，channel增加翻倍(图片来自CSDN)\n![vgg图片](https://img-blog.csdnimg.cn/20190725104625128.png) "},{"cell_type":"code","source":"!pwd","metadata":{"id":"03C85795147A409BB0003867CD7072A8","notebookId":"630f63b4b6c7a36d1d79cd76","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"/home/mw/project\r\n"}],"execution_count":47},{"cell_type":"markdown","id":"3721b923","metadata":{"id":"8728D64705B64C21BBC883BEB2CBE8B6","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"source":"实现一个vgg-A，也就是9层的神经网络"},{"cell_type":"code","execution_count":32,"id":"9ccd52cc","metadata":{"id":"ABACB3618D99456CB371B273CF0366BF","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"vgg_9 = models.Sequential([\n    layers.experimental.preprocessing.Rescaling(1./255,input_shape=(img_height, img_width, 3)),\n    layers.Conv2D(64, (3, 3),padding='same', activation='relu', input_shape=(img_height, img_width, 3)),\n    layers.MaxPool2D(pool_size=(2,2)),\n    layers.Conv2D(128,(3,3),padding='same',activation='relu'),\n    layers.MaxPool2D(pool_size=(2,2)),\n    layers.Conv2D(256,(3,3),padding='same',activation='relu'),\n    layers.Conv2D(256,(3,3),padding='same',activation='relu'),\n    layers.MaxPool2D(pool_size=(2,2)),\n    layers.Conv2D(512,(3,3),padding='same',activation='relu'),\n    layers.Conv2D(512,(3,3),padding='same',activation='relu'),\n    layers.MaxPool2D(pool_size=(2,2)),\n    layers.Conv2D(512,(3,3),padding='same',activation='relu'),\n    layers.Conv2D(512,(3,3),padding='same',activation='relu'),\n    layers.MaxPool2D(pool_size=(2,2)),\n    layers.Dropout(0.7),\n    layers.Flatten(), \n    layers.Dense(4096,activation='relu'),\n    #layers.Dropout(0.8),# 训练的时候发现太容易过拟合了，全连接层加了一个dropout防止过拟合\n    layers.Dense(4096,activation='relu'),\n    layers.Dense(len(class_names)),\n    \n])"},{"cell_type":"code","execution_count":33,"id":"73c5c232","metadata":{"id":"C1CC6F26A2714F4EB388ED4CA8A8F9D8","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"# optimizer = tf.keras.optimizers.Adam(lr=0.01)\n# vgg_9.compile(optimizer=optimizer,\n#               loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n#               metrics=['accuracy'])\n# 经过不断调试发现优化器使用Adam loss不下降accuracy不提升。改用sgd优化器。\nvgg_9.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              optimizer = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n              metrics=['accuracy'])\n"},{"cell_type":"code","execution_count":34,"id":"38045bd4","metadata":{"id":"BABE289B28594708B23EFAFE72E29265","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[],"source":"checkpointer = ModelCheckpoint('vgg_best_model.h5',\n                                monitor='val_accuracy',\n                                verbose=1,\n                                save_best_only=True,\n                                save_weights_only=True)"},{"cell_type":"code","execution_count":35,"id":"b5f42848","metadata":{"id":"FFCF63DCE08B438F8F9D3986E17FD6AA","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/50\n51/51 [==============================] - 12s 231ms/step - loss: 2.8298 - accuracy: 0.1034 - val_loss: 2.8049 - val_accuracy: 0.1389\n\nEpoch 00001: val_accuracy improved from -inf to 0.13889, saving model to vgg_best_model.h5\nEpoch 2/50\n51/51 [==============================] - 11s 225ms/step - loss: 2.8256 - accuracy: 0.1001 - val_loss: 2.7960 - val_accuracy: 0.1389\n\nEpoch 00002: val_accuracy did not improve from 0.13889\nEpoch 3/50\n51/51 [==============================] - 12s 227ms/step - loss: 2.8022 - accuracy: 0.1179 - val_loss: 2.7876 - val_accuracy: 0.1389\n\nEpoch 00003: val_accuracy did not improve from 0.13889\nEpoch 4/50\n51/51 [==============================] - 12s 228ms/step - loss: 2.7895 - accuracy: 0.1163 - val_loss: 2.7117 - val_accuracy: 0.1667\n\nEpoch 00004: val_accuracy improved from 0.13889 to 0.16667, saving model to vgg_best_model.h5\nEpoch 5/50\n51/51 [==============================] - 11s 225ms/step - loss: 2.7448 - accuracy: 0.1202 - val_loss: 2.8219 - val_accuracy: 0.1389\n\nEpoch 00005: val_accuracy did not improve from 0.16667\nEpoch 6/50\n51/51 [==============================] - 11s 222ms/step - loss: 2.8230 - accuracy: 0.1078 - val_loss: 2.8015 - val_accuracy: 0.1389\n\nEpoch 00006: val_accuracy did not improve from 0.16667\nEpoch 7/50\n51/51 [==============================] - 11s 224ms/step - loss: 2.8094 - accuracy: 0.1108 - val_loss: 2.7796 - val_accuracy: 0.1389\n\nEpoch 00007: val_accuracy did not improve from 0.16667\nEpoch 8/50\n51/51 [==============================] - 11s 226ms/step - loss: 2.7617 - accuracy: 0.1134 - val_loss: 2.8381 - val_accuracy: 0.0444\n\nEpoch 00008: val_accuracy did not improve from 0.16667\nEpoch 9/50\n51/51 [==============================] - 11s 224ms/step - loss: 2.8189 - accuracy: 0.0882 - val_loss: 2.7496 - val_accuracy: 0.1389\n\nEpoch 00009: val_accuracy did not improve from 0.16667\nEpoch 10/50\n51/51 [==============================] - 11s 225ms/step - loss: 2.7532 - accuracy: 0.1277 - val_loss: 2.8105 - val_accuracy: 0.1389\n\nEpoch 00010: val_accuracy did not improve from 0.16667\nEpoch 11/50\n51/51 [==============================] - 11s 224ms/step - loss: 2.8072 - accuracy: 0.1127 - val_loss: 2.8241 - val_accuracy: 0.1444\n\nEpoch 00011: val_accuracy did not improve from 0.16667\nEpoch 12/50\n51/51 [==============================] - 12s 226ms/step - loss: 2.6755 - accuracy: 0.1427 - val_loss: 2.8344 - val_accuracy: 0.0444\n\nEpoch 00012: val_accuracy did not improve from 0.16667\nEpoch 13/50\n51/51 [==============================] - 11s 223ms/step - loss: 2.8222 - accuracy: 0.0878 - val_loss: 2.7979 - val_accuracy: 0.1389\n\nEpoch 00013: val_accuracy did not improve from 0.16667\nEpoch 14/50\n51/51 [==============================] - 11s 223ms/step - loss: 2.8094 - accuracy: 0.1203 - val_loss: 2.8017 - val_accuracy: 0.1389\n\nEpoch 00014: val_accuracy did not improve from 0.16667\nEpoch 15/50\n51/51 [==============================] - 11s 224ms/step - loss: 2.8209 - accuracy: 0.1007 - val_loss: 2.8005 - val_accuracy: 0.1389\n\nEpoch 00015: val_accuracy did not improve from 0.16667\nEpoch 16/50\n51/51 [==============================] - 11s 226ms/step - loss: 2.8190 - accuracy: 0.1014 - val_loss: 2.7883 - val_accuracy: 0.1389\n\nEpoch 00016: val_accuracy did not improve from 0.16667\nEpoch 17/50\n51/51 [==============================] - 12s 228ms/step - loss: 2.7762 - accuracy: 0.0912 - val_loss: 2.5810 - val_accuracy: 0.1667\n\nEpoch 00017: val_accuracy did not improve from 0.16667\nEpoch 18/50\n51/51 [==============================] - 12s 226ms/step - loss: 2.7429 - accuracy: 0.1276 - val_loss: 2.6882 - val_accuracy: 0.1778\n\nEpoch 00018: val_accuracy improved from 0.16667 to 0.17778, saving model to vgg_best_model.h5\nEpoch 19/50\n51/51 [==============================] - 11s 225ms/step - loss: 2.6352 - accuracy: 0.1459 - val_loss: 2.5478 - val_accuracy: 0.2000\n\nEpoch 00019: val_accuracy improved from 0.17778 to 0.20000, saving model to vgg_best_model.h5\nEpoch 20/50\n51/51 [==============================] - 11s 225ms/step - loss: 2.4905 - accuracy: 0.1834 - val_loss: 2.4636 - val_accuracy: 0.2222\n\nEpoch 00020: val_accuracy improved from 0.20000 to 0.22222, saving model to vgg_best_model.h5\nEpoch 21/50\n51/51 [==============================] - 11s 224ms/step - loss: 2.2980 - accuracy: 0.2547 - val_loss: 2.3475 - val_accuracy: 0.2389\n\nEpoch 00021: val_accuracy improved from 0.22222 to 0.23889, saving model to vgg_best_model.h5\nEpoch 22/50\n51/51 [==============================] - 11s 222ms/step - loss: 2.2453 - accuracy: 0.2653 - val_loss: 2.3093 - val_accuracy: 0.2389\n\nEpoch 00022: val_accuracy did not improve from 0.23889\nEpoch 23/50\n51/51 [==============================] - 11s 224ms/step - loss: 2.1214 - accuracy: 0.2931 - val_loss: 2.3323 - val_accuracy: 0.2111\n\nEpoch 00023: val_accuracy did not improve from 0.23889\nEpoch 24/50\n51/51 [==============================] - 11s 224ms/step - loss: 2.0921 - accuracy: 0.3152 - val_loss: 2.1672 - val_accuracy: 0.3167\n\nEpoch 00024: val_accuracy improved from 0.23889 to 0.31667, saving model to vgg_best_model.h5\nEpoch 25/50\n51/51 [==============================] - 11s 223ms/step - loss: 1.9647 - accuracy: 0.3424 - val_loss: 2.1819 - val_accuracy: 0.3111\n\nEpoch 00025: val_accuracy did not improve from 0.31667\nEpoch 26/50\n51/51 [==============================] - 11s 225ms/step - loss: 1.8449 - accuracy: 0.3771 - val_loss: 2.0748 - val_accuracy: 0.3167\n\nEpoch 00026: val_accuracy did not improve from 0.31667\nEpoch 27/50\n51/51 [==============================] - 12s 227ms/step - loss: 1.7713 - accuracy: 0.3964 - val_loss: 2.0465 - val_accuracy: 0.2944\n\nEpoch 00027: val_accuracy did not improve from 0.31667\nEpoch 28/50\n51/51 [==============================] - 12s 228ms/step - loss: 1.6229 - accuracy: 0.4590 - val_loss: 1.9723 - val_accuracy: 0.3556\n\nEpoch 00028: val_accuracy improved from 0.31667 to 0.35556, saving model to vgg_best_model.h5\nEpoch 29/50\n51/51 [==============================] - 11s 225ms/step - loss: 1.5258 - accuracy: 0.4822 - val_loss: 2.1672 - val_accuracy: 0.3111\n\nEpoch 00029: val_accuracy did not improve from 0.35556\nEpoch 30/50\n51/51 [==============================] - 12s 227ms/step - loss: 1.3954 - accuracy: 0.5245 - val_loss: 2.1961 - val_accuracy: 0.2889\n\nEpoch 00030: val_accuracy did not improve from 0.35556\nEpoch 31/50\n51/51 [==============================] - 12s 227ms/step - loss: 1.2462 - accuracy: 0.5914 - val_loss: 2.1518 - val_accuracy: 0.3778\n\nEpoch 00031: val_accuracy improved from 0.35556 to 0.37778, saving model to vgg_best_model.h5\nEpoch 32/50\n51/51 [==============================] - 11s 226ms/step - loss: 1.0841 - accuracy: 0.6321 - val_loss: 2.0935 - val_accuracy: 0.3611\n\nEpoch 00032: val_accuracy did not improve from 0.37778\nEpoch 33/50\n51/51 [==============================] - 12s 227ms/step - loss: 0.9759 - accuracy: 0.6624 - val_loss: 2.0526 - val_accuracy: 0.3889\n\nEpoch 00033: val_accuracy improved from 0.37778 to 0.38889, saving model to vgg_best_model.h5\nEpoch 34/50\n51/51 [==============================] - 11s 226ms/step - loss: 0.8434 - accuracy: 0.7278 - val_loss: 2.2555 - val_accuracy: 0.4000\n\nEpoch 00034: val_accuracy improved from 0.38889 to 0.40000, saving model to vgg_best_model.h5\nEpoch 35/50\n51/51 [==============================] - 11s 224ms/step - loss: 0.6231 - accuracy: 0.7898 - val_loss: 2.4116 - val_accuracy: 0.4056\n\nEpoch 00035: val_accuracy improved from 0.40000 to 0.40556, saving model to vgg_best_model.h5\nEpoch 36/50\n51/51 [==============================] - 11s 223ms/step - loss: 0.5786 - accuracy: 0.8005 - val_loss: 2.3741 - val_accuracy: 0.3833\n\nEpoch 00036: val_accuracy did not improve from 0.40556\nEpoch 37/50\n51/51 [==============================] - 11s 224ms/step - loss: 0.4636 - accuracy: 0.8405 - val_loss: 2.3348 - val_accuracy: 0.4056\n\nEpoch 00037: val_accuracy did not improve from 0.40556\nEpoch 38/50\n51/51 [==============================] - 11s 224ms/step - loss: 0.4380 - accuracy: 0.8586 - val_loss: 2.3181 - val_accuracy: 0.4056\n\nEpoch 00038: val_accuracy did not improve from 0.40556\nEpoch 39/50\n51/51 [==============================] - 11s 224ms/step - loss: 0.3539 - accuracy: 0.8885 - val_loss: 2.5614 - val_accuracy: 0.4167\n\nEpoch 00039: val_accuracy improved from 0.40556 to 0.41667, saving model to vgg_best_model.h5\nEpoch 40/50\n51/51 [==============================] - 11s 222ms/step - loss: 0.3471 - accuracy: 0.8958 - val_loss: 2.7971 - val_accuracy: 0.4000\n\nEpoch 00040: val_accuracy did not improve from 0.41667\nEpoch 41/50\n51/51 [==============================] - 11s 222ms/step - loss: 0.3194 - accuracy: 0.8901 - val_loss: 3.0648 - val_accuracy: 0.4444\n\nEpoch 00041: val_accuracy improved from 0.41667 to 0.44444, saving model to vgg_best_model.h5\nEpoch 42/50\n51/51 [==============================] - 11s 221ms/step - loss: 0.2845 - accuracy: 0.9085 - val_loss: 3.0134 - val_accuracy: 0.4167\n\nEpoch 00042: val_accuracy did not improve from 0.44444\nEpoch 43/50\n51/51 [==============================] - 11s 221ms/step - loss: 0.2196 - accuracy: 0.9186 - val_loss: 3.0722 - val_accuracy: 0.4167\n\nEpoch 00043: val_accuracy did not improve from 0.44444\nEpoch 44/50\n51/51 [==============================] - 11s 221ms/step - loss: 0.1955 - accuracy: 0.9298 - val_loss: 3.1510 - val_accuracy: 0.4833\n\nEpoch 00044: val_accuracy improved from 0.44444 to 0.48333, saving model to vgg_best_model.h5\nEpoch 45/50\n51/51 [==============================] - 11s 220ms/step - loss: 0.1771 - accuracy: 0.9373 - val_loss: 3.3424 - val_accuracy: 0.4556\n\nEpoch 00045: val_accuracy did not improve from 0.48333\nEpoch 46/50\n51/51 [==============================] - 11s 221ms/step - loss: 0.1626 - accuracy: 0.9469 - val_loss: 3.2558 - val_accuracy: 0.4333\n\nEpoch 00046: val_accuracy did not improve from 0.48333\nEpoch 47/50\n51/51 [==============================] - 11s 221ms/step - loss: 0.1055 - accuracy: 0.9642 - val_loss: 3.1726 - val_accuracy: 0.4056\n\nEpoch 00047: val_accuracy did not improve from 0.48333\nEpoch 48/50\n51/51 [==============================] - 11s 222ms/step - loss: 0.1520 - accuracy: 0.9566 - val_loss: 3.9656 - val_accuracy: 0.4500\n\nEpoch 00048: val_accuracy did not improve from 0.48333\nEpoch 49/50\n51/51 [==============================] - 11s 222ms/step - loss: 0.1569 - accuracy: 0.9572 - val_loss: 3.3600 - val_accuracy: 0.4278\n\nEpoch 00049: val_accuracy did not improve from 0.48333\nEpoch 50/50\n51/51 [==============================] - 11s 222ms/step - loss: 0.1396 - accuracy: 0.9577 - val_loss: 2.8770 - val_accuracy: 0.4167\n\nEpoch 00050: val_accuracy did not improve from 0.48333\n"}],"source":"vgg_history = vgg_9.fit(train_ds,\n                    validation_data=val_ds,\n                    epochs=50,callbacks=[checkpointer])"},{"cell_type":"code","execution_count":36,"id":"74c6294e","metadata":{"id":"9995E17C98324DDA83BF2CA1D5F8B979","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"630f63b4b6c7a36d1d79cd76","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x288 with 2 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/9995E17C98324DDA83BF2CA1D5F8B979/rhkc8vtvmj.png\">"},"metadata":{"needs_background":"light"},"transient":{}}],"source":"acc = vgg_history.history['accuracy']\nval_acc = vgg_history.history['val_accuracy']\n\nloss = vgg_history.history['loss']\nval_loss = vgg_history.history['val_loss']\n\nepochs_range = range(len(loss))\n\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()"},{"cell_type":"markdown","source":"# 总结：\n1.当loss和accuracy不下降时，进行问题排查：\n模型结构是否有问题\n权重的初始化\n你的数据和label是否正确\n优化器的使用是否合理\n损失函数是否正确\n学习率是否过大\n这里进行尝试，最开始用的adm优化器，换成了sgd优化器。\n\n2.正则化尝试：\n\t这里主要试验了dropout正则化，发现当Dropout设置过大时，会造成欠拟合问题。","metadata":{"id":"681210F9AEB84FD1854CD4F3E81FEDA9","notebookId":"630f63b4b6c7a36d1d79cd76","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true}},{"cell_type":"code","source":"","metadata":{"id":"71B0D552C8494C6A8D03BBAEF61FEE48","notebookId":"630f63b4b6c7a36d1d79cd76","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":5}